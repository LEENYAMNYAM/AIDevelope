{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3849ed3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.7.1-cp312-cp312-win_amd64.whl (216.1 MB)\n",
      "   ---------------------------------------- 0.0/216.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 7.3/216.1 MB 75.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 26.7/216.1 MB 65.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 30.4/216.1 MB 66.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 34.3/216.1 MB 41.9 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 48.0/216.1 MB 47.0 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 57.1/216.1 MB 46.1 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 65.3/216.1 MB 44.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 69.2/216.1 MB 44.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 81.0/216.1 MB 43.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 91.0/216.1 MB 43.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 98.6/216.1 MB 43.7 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 108.0/216.1 MB 42.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 113.2/216.1 MB 43.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 115.9/216.1 MB 39.6 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 127.1/216.1 MB 40.6 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 138.4/216.1 MB 41.3 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 138.4/216.1 MB 41.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 146.8/216.1 MB 39.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 147.8/216.1 MB 38.1 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 153.1/216.1 MB 37.5 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 154.1/216.1 MB 35.8 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 161.2/216.1 MB 35.0 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 169.3/216.1 MB 35.2 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 171.7/216.1 MB 34.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 180.6/216.1 MB 34.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 189.8/216.1 MB 34.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 199.2/216.1 MB 35.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 204.2/216.1 MB 34.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 209.7/216.1 MB 34.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  216.0/216.1 MB 34.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  216.0/216.1 MB 34.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  216.0/216.1 MB 34.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  216.0/216.1 MB 34.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 216.1/216.1 MB 31.1 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------  6.3/6.3 MB 32.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 27.7 MB/s eta 0:00:00\n",
      "Installing collected packages: sympy, torch\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed sympy-1.14.0 torch-2.7.1\n"
     ]
    }
   ],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0afd9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2622ef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([[4, 5],\n",
      "        [6, 7]])\n",
      "tensor([1.2000, 2.3000, 3.4000])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1, 2, 3], dtype=torch.float32)  # dtype 은 실수로 지정\n",
    "t2 = torch.tensor([[4, 5], [6, 7]])\n",
    "t3 = torch.tensor([1.2, 2.3, 3.4])\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2637de9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3])\n",
      "tensor([1, 2, 3], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "tf = torch.FloatTensor([1, 2, 3])  # FloatTensor로 실수 텐서 생성\n",
    "f1 = torch.LongTensor([1, 2, 3])  # LongTensor로 정수 텐서 생성 ( int64 )\n",
    "tb = torch.ByteTensor([1, 2, 3])  # ByteTensor로 바이트 텐서 생성\n",
    "print(tf)\n",
    "print(f1)\n",
    "print(tb)\n",
    "# 텐서의 데이터 타입 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae9e47c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,2,3], [4,5,6]])\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb780eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# NumPy 배열을 PyTorch 텐서로 변환\n",
    "x= torch.from_numpy(a)  # NumPy 배열을 PyTorch 텐서로 변환\n",
    "print(x)\n",
    "print(type(x))  # 텐서의 타입 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b34123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# PyTorch 텐서를 NumPy 배열로 변환\n",
    "b = x.numpy()\n",
    "print(b)\n",
    "print(type(b))  # NumPy 배열의 타입 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df771caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "<class 'torch.Tensor'> torch.int64\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3], [4,5,6]])\n",
    "print(x)\n",
    "print(type(x), x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "792e8e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# PyTorch 텐서의 데이터 타입 변경(long -> float)\n",
    "y=x.float()\n",
    "print(y)\n",
    "print(y.dtype)  # dtype이 float32로 변경됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8da6d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# PyTorch 텐서의 데이터 타입 변경(float -> long)\n",
    "z=x.long()\n",
    "print(z)\n",
    "print(z.dtype)  # dtype이 int64로 변경됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37635248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.uint8)\n",
      "torch.uint8\n"
     ]
    }
   ],
   "source": [
    "# PyTorch 텐서의 데이터 타입 변경(float -> byte)\n",
    "z1 = y.byte()\n",
    "print(z1)\n",
    "print(z1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fc24c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2],\n",
       "        [ 3,  4]],\n",
       "\n",
       "       [[ 5,  6],\n",
       "        [ 7,  8]],\n",
       "\n",
       "       [[ 9, 10],\n",
       "        [11, 12]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(1,13).reshape(3,2,2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9d5acd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 2])\n",
      "torch.Size([3, 2, 2])\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "x= torch.from_numpy(a)  # NumPy 배열을 PyTorch 텐서로 변환\n",
    "print(x.shape)  # 텐서의 형태 확인\n",
    "print(x.size())  # 텐서의 크기 확인\n",
    "print(x.dim())  # 텐서의 차원 수 확인\n",
    "print(x.ndim)  # 텐서의 차원 수 확인 (dim과 동일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c05fefc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(x.size(0))  # 첫 번째 차원의 크기\n",
    "print(x.size(1))  # 두 번째 차원의 크기\n",
    "print(x.size(2))  # 세 번째 차원의 크기\n",
    "print(x.size(-1))  # 마지막 차원의 크기 (세 번째 차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a98c9809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6,  8],\n",
      "        [10, 12]])\n",
      "tensor([[-4, -4],\n",
      "        [-4, -4]])\n",
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor([[2, 4],\n",
      "        [6, 8]])\n",
      "tensor([[0.5000, 1.0000],\n",
      "        [1.5000, 2.0000]])\n",
      "tensor([[3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[-1,  0],\n",
      "        [ 1,  2]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[0, 0],\n",
      "        [0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 기본 연산\n",
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "y = torch.tensor([[5, 6], [7, 8]])\n",
    "# 덧셈\n",
    "print(x + y) # 결과: tensor([[ 6,  8], [10, 12]])\n",
    "# 뺄셈\n",
    "print(x - y) # 결과: tensor([[-4, -4], [-4, -4]])\n",
    "# 곱셈 (원소별 곱셈)\n",
    "print(x * y) # 결과: tensor([[ 5, 12], [21, 32]])\n",
    "# 나눗셈 (원소별 나눗셈)\n",
    "print(x / y) # 결과: tensor([[0.2000, 0.3333], [0.4286, 0.5000]])\n",
    "# 행렬 곱셈\n",
    "print(torch.matmul(x, y)) # 결과: tensor([[19, 22], [43, 50]])\n",
    "# 행렬 곱셈 (연산자 사용)\n",
    "print(x @ y) # 결과: tensor([[19, 22], [43, 50]])\n",
    "# 스칼라 곱셈\n",
    "print(x * 2) # 결과: tensor([[2, 4], [6, 8]])\n",
    "# 스칼라 나눗셈\n",
    "print(x / 2) # 결과: tensor([[0.5000, 1.0000], [1.5000, 2.0000]])\n",
    "# 스칼라 덧셈\n",
    "print(x + 2) # 결과: tensor([[3, 4], [5, 6]])\n",
    "# 스칼라 뺄셈\n",
    "print(x - 2) # 결과: tensor([[-1,  0], [ 1,  2]])\n",
    "# 나머지 구하기\n",
    "print(x % y) # 결과: tensor([[1, 2], [3, 4]])\n",
    "# 정수몫 나눗셈\n",
    "print(x // y)   # 결과: tensor([[0, 0], [0, 0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7c8ba34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False],\n",
      "        [False, False]])\n",
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[False, False],\n",
      "        [False, False]])\n",
      "tensor([[False, False],\n",
      "        [False, False]])\n",
      "tensor([[False, False],\n",
      "        [False, False]])\n",
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[False, False],\n",
      "        [False, False]])\n",
      "tensor([[False, False],\n",
      "        [False, False]])\n",
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[False, False],\n",
      "        [False, False]])\n",
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "print(a == b)  # 두 텐서가 같은지 비교\n",
    "print(a != b)  # 두 텐서가 다른지 비교\n",
    "print(a < b)   # a의 원소가 b의 원소보다 작은지 비교\n",
    "print(a <= b)  # a의 원소가 b의 원소보다 작거나 같은지 비교\n",
    "print(a > b)   # a의 원소가 b의 원소보다 큰지 비교\n",
    "print(a >= b)  # a의 원소가 b의 원소보다 크거나 같은지 비교\n",
    "print(a.eq(b))  # a와 b가 같은지 비교 (eq는 equal의 약자)\n",
    "print(a.ne(b))  # a와 b가 다른지 비교 (ne는 not equal의 약자)\n",
    "print(a.lt(b))   # a의 원소가 b의 원소보다 작은지 비교 (lt는 less than의 약자\n",
    "print(a.le(b))   # a의 원소가 b의 원소보다 작거나 같은지 비교 (le는 less than or equal의 약자\n",
    "print(a.gt(b))   # a의 원소가 b의 원소보다 큰지 비교 (gt는 greater than의 약자\n",
    "print(a.ge(b))   # a의 원소가 b의 원소보다 크거나 같은지 비교 (ge는 greater than or equal의 약자\n",
    "# 논리 연산\n",
    "print(a.logical_and(b))  # a와 b의 원소가 모두 True인 경우 True\n",
    "print(a.logical_or(b))   # a와 b의 원소 중 하나라도 True인 경우 True\n",
    "# 논리 연산 (and, or, not)\n",
    "print(torch.logical_and(a, b))  # a와 b의 원소가 모두 True인 경우 True\n",
    "print(torch.logical_or(a, b))   # a와 b의 원소 중 하나라도 True인 경우 True\n",
    "# 논리 부정\n",
    "print(torch.logical_not(a))  # a의 원소가 False인 경우 True\n",
    "# 논리 연산 (and, or, not)\n",
    "print(torch.all(a))  # a의 모든 원소가 True인 경우 True\n",
    "print(torch.any(a))  # a의 원소 중 하나라도 True인 경우 True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a536d137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "print(a.mul(b))  # 행렬 곱셈\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85f111a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1, 13).reshape(3, 4)\n",
    "print(a)\n",
    "x = torch.from_numpy(a)  # NumPy 배열을 PyTorch 텐서로 변환\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bea6a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(78)\n",
      "tensor([15, 18, 21, 24])\n",
      "tensor([10, 26, 42])\n",
      "tensor([10, 26, 42])\n"
     ]
    }
   ],
   "source": [
    "print(x.sum())  # 모든 원소의 합\n",
    "print(x.sum(dim=0))  # 각 열의 합\n",
    "print(x.sum(dim=1))  # 각 행의 합\n",
    "print(x.sum(dim=-1))  # 마지막 차원의 합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03242805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "y = torch.tensor([1, 2, 3, 4])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce30444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  4,  6,  8],\n",
      "        [ 6,  8, 10, 12],\n",
      "        [10, 12, 14, 16]])\n"
     ]
    }
   ],
   "source": [
    "print(x+y)  # 브로드캐스팅을 이용한 덧셈\n",
    "# 계산이 가능하도록 차원을 맞춰줘야함.(차원이 안맞으면 계산이 불가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a56b73ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2]\n",
      "  [ 3  4]]\n",
      "\n",
      " [[ 5  6]\n",
      "  [ 7  8]]\n",
      "\n",
      " [[ 9 10]\n",
      "  [11 12]]]\n",
      "tensor([[[ 1,  2],\n",
      "         [ 3,  4]],\n",
      "\n",
      "        [[ 5,  6],\n",
      "         [ 7,  8]],\n",
      "\n",
      "        [[ 9, 10],\n",
      "         [11, 12]]], dtype=torch.int32)\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1, 13).reshape(3, 2, 2)\n",
    "print(a)\n",
    "x = torch.from_numpy(a)  # NumPy 배열을 PyTorch 텐서로 변환\n",
    "y = torch.tensor([[1, 2], [3, 4]])  # 2차원 텐서\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac9332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2],\n",
      "         [ 3,  4]],\n",
      "\n",
      "        [[ 5,  6],\n",
      "         [ 7,  8]],\n",
      "\n",
      "        [[ 9, 10],\n",
      "         [11, 12]]], dtype=torch.int32)\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]], dtype=torch.int32)\n",
      "tensor([[ 1,  2,  3,  4,  5,  6],\n",
      "        [ 7,  8,  9, 10, 11, 12]], dtype=torch.int32)\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]], dtype=torch.int32)\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]], dtype=torch.int32)\n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "# view()와 reshape()를 사용하여 텐서의 형태를 변경할 수 있습니다.(두개 의 차이는 reshape()는 메모리 복사를 하지 않지만, view()는 메모리 복사를 합니다.)\n",
    "print(x.view(3, 4))  # 3x4 형태로 변환\n",
    "print(x.view(2, 6))  # 2x6 형태로 변환\n",
    "print(x.view(3, -1))  # -1을 사용하여 자동으로 차원 계산\n",
    "print(x.view(-1, 4))  # -1을 사용하여 자동으로 차원 계산\n",
    "print(x.reshape(4, 3))  # 4x3 형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd178ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3,  4]],\n",
      "\n",
      "        [[ 5,  6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11, 12]]], dtype=torch.int32)\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]], dtype=torch.int32)\n",
      "tensor([[[ 1,  2,  3,  4]],\n",
      "\n",
      "        [[ 5,  6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11, 12]]], dtype=torch.int32)\n",
      "tensor([[[ 1],\n",
      "         [ 2],\n",
      "         [ 3],\n",
      "         [ 4]],\n",
      "\n",
      "        [[ 5],\n",
      "         [ 6],\n",
      "         [ 7],\n",
      "         [ 8]],\n",
      "\n",
      "        [[ 9],\n",
      "         [10],\n",
      "         [11],\n",
      "         [12]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Squeeze() : 텐서의 차원 중 크기가 1인 차원을 제거합니다.\n",
    "# Unsqueeze() : 텐서에 새로운 차원을 추가합니다.\n",
    "\n",
    "y = x.view(3, 1, 4)\n",
    "print(y)\n",
    "z1 = y.squeeze()  # 크기가 1인 차원을 제거하여 3x4 형태로 변환\n",
    "print(z1)  # 크기가 1인 차원을 제거하여 3x4 형태로 변환\n",
    "z2 = z1.unsqueeze(1) \n",
    "print(z2)  # 두 번째 차원에 새로운 차원을 추가하여 1x3x4 형태로 변환\n",
    "z3 = z1.unsqueeze(-1)  \n",
    "print(z3) # 마지막 차원에 새로운 차원을 추가하여 3x4x1 형태로 변환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c602f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([1, 2], dtype=torch.int32)\n",
      "tensor(1, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(x[0])  # 첫 번째 행을 선택\n",
    "print(x[0, 0]) # 첫 번째 행의 첫 번째 열을 선택\n",
    "print(x[0, 0, 0])  # 첫 번째 행의 첫 번째 열의 첫 번째 깊이 값을 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fec558b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([2, 4], dtype=torch.int32)\n",
      "tensor([6, 8], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(x[0,:])   # 첫 번째 행의 모든 열을 선택\n",
    "print(x[0, : , -1])  # 첫 번째 행의 마지막 열을 선택\n",
    "print(x[1,:,-1])  # 두 번째 행의 마지막 열을 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "18045abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12],\n",
      "        [13, 14, 15, 16],\n",
      "        [17, 18, 19, 20],\n",
      "        [21, 22, 23, 24],\n",
      "        [25, 26, 27, 28],\n",
      "        [29, 30, 31, 32],\n",
      "        [33, 34, 35, 36],\n",
      "        [37, 38, 39, 40]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1, 41).reshape(10,4)\n",
    "x = torch.from_numpy(a)  # NumPy 배열을 PyTorch 텐서로 변환\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c746caa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12],\n",
      "        [13, 14, 15, 16]], dtype=torch.int32)\n",
      "torch.Size([4, 4])\n",
      "tensor([[17, 18, 19, 20],\n",
      "        [21, 22, 23, 24],\n",
      "        [25, 26, 27, 28],\n",
      "        [29, 30, 31, 32]], dtype=torch.int32)\n",
      "torch.Size([4, 4])\n",
      "tensor([[33, 34, 35, 36],\n",
      "        [37, 38, 39, 40]], dtype=torch.int32)\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "split_x = torch.split(x, 4, dim=0)  # 첫 번째 차원(행)을 기준으로 2개씩 나눔\n",
    "# print(split_x)  # 나눠진 텐서들 출력\n",
    "for  sx in split_x:\n",
    "    print(sx)  # 각 나눠진 텐서의 크기 출력\n",
    "    print(sx.shape)  # 각 나눠진 텐서의 형태 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "22a1bc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]], dtype=torch.int32)\n",
      "torch.Size([2, 4])\n",
      "tensor([[ 9, 10, 11, 12],\n",
      "        [13, 14, 15, 16]], dtype=torch.int32)\n",
      "torch.Size([2, 4])\n",
      "tensor([[17, 18, 19, 20],\n",
      "        [21, 22, 23, 24]], dtype=torch.int32)\n",
      "torch.Size([2, 4])\n",
      "tensor([[25, 26, 27, 28],\n",
      "        [29, 30, 31, 32]], dtype=torch.int32)\n",
      "torch.Size([2, 4])\n",
      "tensor([[33, 34, 35, 36],\n",
      "        [37, 38, 39, 40]], dtype=torch.int32)\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "chunks = x.chunk(5, dim=0)  # 첫 번째 차원(행)을 기준으로 4개로 나눔\n",
    "for chunk in chunks:\n",
    "    print(chunk)  # 각 나눠진 텐서의 크기 출력\n",
    "    print(chunk.shape)  # 각 나눠진 텐서의 형태 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "43a170e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2],\n",
      "         [ 3,  4]],\n",
      "\n",
      "        [[ 5,  6],\n",
      "         [ 7,  8]],\n",
      "\n",
      "        [[ 9, 10],\n",
      "         [11, 12]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,13).reshape(3,2,2)\n",
    "x = torch.from_numpy(a)  # NumPy 배열을 PyTorch 텐서로 변환\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a88650a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 9, 10],\n",
      "         [11, 12]],\n",
      "\n",
      "        [[ 5,  6],\n",
      "         [ 7,  8]],\n",
      "\n",
      "        [[ 1,  2],\n",
      "         [ 3,  4]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "indices = torch.LongTensor([2,1,0]) # 인덱스 텐서 생성\n",
    "y = x.index_select(0, indices)  # 첫 번째 차원(행)을 기준으로 인덱스 선택\n",
    "print(y)  # 선택된 행 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "80e9b7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]], dtype=torch.int32)\n",
      "tensor([[11, 12, 13, 14],\n",
      "        [15, 16, 17, 18],\n",
      "        [19, 20, 21, 22]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,13).reshape(3,4)\n",
    "b = np.arange(11,23).reshape(3,4)\n",
    "x = torch.from_numpy(a)  # NumPy 배열을 PyTorch 텐서로 변환\n",
    "y = torch.from_numpy(b)  # NumPy 배열을 PyTorch 텐서로 변환\n",
    "print(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "99540717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12],\n",
      "        [11, 12, 13, 14],\n",
      "        [15, 16, 17, 18],\n",
      "        [19, 20, 21, 22]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "z = torch.cat((x, y), dim=0)  # 첫 번째 차원(행)을 기준으로 연결\n",
    "print(z)  # 연결된 텐서 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f02ef447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4, 11, 12, 13, 14],\n",
      "        [ 5,  6,  7,  8, 15, 16, 17, 18],\n",
      "        [ 9, 10, 11, 12, 19, 20, 21, 22]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "z1 = torch.cat((x, y), dim=1)  # 두 번째 차원(열)을 기준으로 연결\n",
    "print(z1)  # 연결된 텐서 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ced318d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8],\n",
      "         [ 9, 10, 11, 12]],\n",
      "\n",
      "        [[11, 12, 13, 14],\n",
      "         [15, 16, 17, 18],\n",
      "         [19, 20, 21, 22]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "z2 = torch.stack((x, y), dim=0)  # 첫 번째 차원(행)을 기준으로 스택\n",
    "print(z2)  # 스택된 텐서 출력\n",
    "# stack은 새로운 차원을 추가하여 텐서를 쌓는 반면, cat은 기존 차원을 기준으로 텐서를 연결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "83efdb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3,  4],\n",
      "         [11, 12, 13, 14]],\n",
      "\n",
      "        [[ 5,  6,  7,  8],\n",
      "         [15, 16, 17, 18]],\n",
      "\n",
      "        [[ 9, 10, 11, 12],\n",
      "         [19, 20, 21, 22]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "z3 = torch.stack((x, y), dim=1)  # 두 번째 차원(열)을 기준으로 스택\n",
    "print(z3)  # 스택된 텐서 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f249a35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 2])\n",
      "tensor([[[1., 2.]],\n",
      "\n",
      "        [[3., 4.]]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor([[[1, 2]], [[3, 4]]])\n",
    "print(X.size())  # 텐서의 크기 출력\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7ec769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2])\n",
      "tensor([[[1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.]],\n",
      "\n",
      "        [[3., 4.],\n",
      "         [3., 4.],\n",
      "         [3., 4.]]])\n"
     ]
    }
   ],
   "source": [
    "y = X.expand(2, 3, 2)  # 텐서를 확장하여 크기를 변경\n",
    "print(y.size())  # 확장된 텐서의 크기 출력\n",
    "print(y)  # 확장된 텐서 출력\n",
    "# expand()는 메모리를 복사하지 않고, 원래 텐서의 데이터를 재사용하여 크기를 변경합니다.\n",
    "# 따라서 메모리 사용량이 적고, 성능이 향상됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ec987145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11,  9, 18,  1, 14, 19, 13, 16,  4, 17,  0,  2,  8,  5,  3, 12, 10, 15,\n",
      "         6,  7])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randperm(20)  # 0부터 19까지의 랜덤한 순열 생성\n",
    "print(x)  # 랜덤한 순열 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "41fc2ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 8, 20,  6],\n",
      "         [ 4, 12, 16],\n",
      "         [14,  1, 15]],\n",
      "\n",
      "        [[17, 23, 19],\n",
      "         [21, 22,  0],\n",
      "         [ 7, 25,  5]],\n",
      "\n",
      "        [[18, 11,  3],\n",
      "         [26, 13,  9],\n",
      "         [10, 24,  2]]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randperm(3**3).reshape(3,3,3)  # 0부터 26까지의 랜덤한 순열을 3x3x3 형태로 변환\n",
    "print(y)  # 랜덤한 순열 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "067aa128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 1, 1],\n",
      "        [2, 1, 0],\n",
      "        [0, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "y1 = y.argmax(dim=0)  # 첫 번째 차원(행)을 기준으로 최대값의 인덱스 찾기\n",
    "print(y1)  # 최대값의 인덱스 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "892cca2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 0, 1],\n",
      "        [1, 2, 0],\n",
      "        [1, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "y2 = y.argmax(dim=1)  # 두 번째 차원(열)을 기준으로 최대값의 인덱스 찾기\n",
    "print(y2)  # 최대값의 인덱스 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "74f58232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 2],\n",
      "        [1, 1, 1],\n",
      "        [0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "y3 = y.argmax(dim=-1)  # 마지막 차원(깊이)을 기준으로 최대값의 인덱스 찾기\n",
    "print(y3)  # 최대값의 인덱스 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f11f8572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[20,  8],\n",
      "         [16, 12],\n",
      "         [15, 14]],\n",
      "\n",
      "        [[23, 19],\n",
      "         [22, 21],\n",
      "         [25,  7]],\n",
      "\n",
      "        [[18, 11],\n",
      "         [26, 13],\n",
      "         [24, 10]]])\n",
      "tensor([[[1, 0],\n",
      "         [2, 1],\n",
      "         [2, 0]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [1, 0],\n",
      "         [1, 0]],\n",
      "\n",
      "        [[0, 1],\n",
      "         [0, 1],\n",
      "         [1, 0]]])\n"
     ]
    }
   ],
   "source": [
    "value, indices = torch.topk(y, k=2, dim = -1)  # 마지막 차원(깊이)을 기준으로 상위 k개의 값과 인덱스 찾기\n",
    "print(value)  # 상위 k개의 값 출력\n",
    "print(indices)  # 상위 k개의 인덱스 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0c231716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([i for i in range(1, 10)]).view(3, 3)  # 1부터 9까지의 값을 가지는 3x3 텐서 생성\n",
    "print(x)  # 텐서 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "345ba314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False],\n",
      "        [False, False,  True],\n",
      "        [ True,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "mask = x > 5  # 5보다 큰 값을 가지는 마스크 생성\n",
    "print(mask)  # 마스크 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7016ca71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y = x.masked_fill(mask, value=0)  # 마스크에 해당하는 값을 0으로 대체\n",
    "print(y)  # 마스크가 적용된 텐서 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e6ac5c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.ones(2,3))  # 2x3 형태의 텐서 생성\n",
    "print(torch.zeros(2, 3))  # 2x3 형태의 텐서 생성 (모든 값이 0인 텐서)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "84a8b170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.ones_like(x))  # x와 같은 형태의 텐서 생성 (모든 값이 1인 텐서)\n",
    "print(torch.zeros_like(x))  # x와 같은 형태의 텐서 생성 (모든 값이 0인 텐서)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104fb588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
