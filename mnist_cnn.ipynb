{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e66f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69abe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda' :\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f82f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learing_rate = 0.001\n",
    "epochs = 30\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6493bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dsets.MNIST(root='mnist_data',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True\n",
    "                          )\n",
    "mnist_test = dsets.MNIST(root='mnist_data',\n",
    "                          train=False,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1be62c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: mnist_data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: mnist_data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train)\n",
    "print(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "120d5262",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=mnist_train,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True)\n",
    "test_loader = DataLoader(dataset=mnist_test,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1c4cea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for X, Y in test_loader:\n",
    "    print(X.size(), Y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc6945e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # ─────────────────────────────────────────────\n",
    "        # [Layer 1]\n",
    "        # 입력 이미지 크기: (배치크기, 채널=1, 높이=28, 너비=28) → MNIST 흑백 이미지\n",
    "        # Conv2d: (1, 28, 28) → (32, 28, 28)  [채널 1 → 32, 크기는 padding=1로 유지]\n",
    "        # MaxPool2d: (32, 28, 28) → (32, 14, 14) [2x2 풀링으로 크기 절반]\n",
    "        # ─────────────────────────────────────────────\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),  # 3x3 필터, 32개, stride=1\n",
    "            nn.ReLU(),                                             # 활성화 함수\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)                  # 2x2 맥스풀링 (크기 절반)\n",
    "        )\n",
    "        # ─────────────────────────────────────────────\n",
    "        # [Layer 2]\n",
    "        # 입력 크기: (32, 14, 14)\n",
    "        # Conv2d: (32, 14, 14) → (64, 14, 14)  [채널 32 → 64, 크기 유지]\n",
    "        # MaxPool2d: (64, 14, 14) → (64, 7, 7) [2x2 풀링 → 크기 절반]\n",
    "        # ─────────────────────────────────────────────\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # ─────────────────────────────────────────────\n",
    "        # [Fully Connected Layer (FC)]\n",
    "        # Conv 결과: (64, 7, 7) → flatten하면 64×7×7 = 3136 차원\n",
    "        # FC 입력: 3136 → 출력: 10개 클래스 (MNIST 숫자 분류)\n",
    "        # 가중치는 Xavier 방식으로 초기화\n",
    "        # ─────────────────────────────────────────────\n",
    "        self.fc = nn.Linear(7 * 7 * 64, 10, bias=True)\n",
    "        nn.init.xavier_uniform_(self.fc.weight)  # FC 층 가중치 Xavier 초기화\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b03128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "crit = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learing_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6df3aef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=3136, out_features=10, bias=True)\n",
      ")\n",
      "[Parameter containing:\n",
      "tensor([[[[-0.2602,  0.0484,  0.0056],\n",
      "          [ 0.1210, -0.3248, -0.1715],\n",
      "          [ 0.1296, -0.0701,  0.2822]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2063, -0.3326, -0.2659],\n",
      "          [-0.1509, -0.1819,  0.2412],\n",
      "          [-0.2311,  0.2483, -0.2072]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2622,  0.2521, -0.1654],\n",
      "          [-0.2284,  0.3138, -0.2838],\n",
      "          [ 0.2257,  0.0032,  0.0550]]],\n",
      "\n",
      "\n",
      "        [[[-0.1942,  0.1822,  0.0797],\n",
      "          [-0.1015,  0.1407, -0.1863],\n",
      "          [ 0.2450, -0.0700,  0.0707]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2520, -0.0366,  0.1100],\n",
      "          [ 0.1145, -0.2239,  0.3294],\n",
      "          [ 0.1244, -0.1182,  0.1793]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2731,  0.0632,  0.1413],\n",
      "          [-0.2711,  0.2232, -0.1506],\n",
      "          [ 0.1686, -0.1358,  0.0637]]],\n",
      "\n",
      "\n",
      "        [[[-0.2495, -0.3321,  0.1124],\n",
      "          [-0.1877, -0.1823,  0.1162],\n",
      "          [-0.2291,  0.1337, -0.3145]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2966,  0.0945,  0.0940],\n",
      "          [-0.0016,  0.0007,  0.1011],\n",
      "          [ 0.3226, -0.2759,  0.1877]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2249, -0.3146,  0.1405],\n",
      "          [ 0.0392,  0.2260,  0.0940],\n",
      "          [-0.1664, -0.2421, -0.2767]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1199,  0.0351, -0.0846],\n",
      "          [-0.1078,  0.1637, -0.2059],\n",
      "          [ 0.0235, -0.1094, -0.2763]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1572, -0.0653, -0.0880],\n",
      "          [-0.2038, -0.1565, -0.2997],\n",
      "          [-0.1100,  0.1882,  0.0468]]],\n",
      "\n",
      "\n",
      "        [[[-0.1234,  0.2606,  0.2854],\n",
      "          [ 0.2075, -0.0837, -0.1529],\n",
      "          [-0.3313,  0.1960, -0.1013]]],\n",
      "\n",
      "\n",
      "        [[[-0.2772,  0.1334,  0.2250],\n",
      "          [ 0.0617, -0.1882, -0.3220],\n",
      "          [ 0.0830,  0.0410, -0.3283]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3140, -0.2185, -0.0978],\n",
      "          [-0.0193, -0.2151, -0.0292],\n",
      "          [-0.2432,  0.3185,  0.0363]]],\n",
      "\n",
      "\n",
      "        [[[-0.1550, -0.0890, -0.2655],\n",
      "          [ 0.0374, -0.0319,  0.1406],\n",
      "          [ 0.2755,  0.1044,  0.1098]]],\n",
      "\n",
      "\n",
      "        [[[-0.2373,  0.1811,  0.1815],\n",
      "          [ 0.2265, -0.3274,  0.1204],\n",
      "          [-0.2028, -0.2691,  0.0872]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0573, -0.3195,  0.1782],\n",
      "          [-0.1696,  0.0382,  0.2150],\n",
      "          [-0.1026, -0.0797,  0.0287]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2386, -0.2199,  0.3068],\n",
      "          [-0.1878,  0.1276, -0.2771],\n",
      "          [ 0.3052, -0.2332,  0.0461]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0419, -0.0230,  0.1603],\n",
      "          [-0.0252, -0.0278,  0.2549],\n",
      "          [ 0.2050, -0.2329,  0.1822]]],\n",
      "\n",
      "\n",
      "        [[[-0.1219, -0.0027,  0.3152],\n",
      "          [ 0.2273,  0.1543,  0.1916],\n",
      "          [-0.2367, -0.0499, -0.2204]]],\n",
      "\n",
      "\n",
      "        [[[-0.1376, -0.2001,  0.3005],\n",
      "          [ 0.1841,  0.3313, -0.1574],\n",
      "          [-0.0138,  0.2605, -0.0230]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2207, -0.0158, -0.0177],\n",
      "          [ 0.2503, -0.0291,  0.1800],\n",
      "          [ 0.1408,  0.0469,  0.3028]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1442,  0.1927, -0.0578],\n",
      "          [ 0.2154, -0.1561,  0.0483],\n",
      "          [-0.1735, -0.2656, -0.1088]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2117,  0.1345,  0.3099],\n",
      "          [ 0.0132,  0.2444,  0.2273],\n",
      "          [-0.1503,  0.2755, -0.1148]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2465, -0.3222, -0.2684],\n",
      "          [-0.3102, -0.0141,  0.1812],\n",
      "          [-0.2875,  0.1009,  0.2035]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2748, -0.0996,  0.3004],\n",
      "          [ 0.3134, -0.3176,  0.3216],\n",
      "          [-0.0324, -0.0968, -0.0186]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1458,  0.1940,  0.1610],\n",
      "          [ 0.0278,  0.3119,  0.1847],\n",
      "          [-0.0216,  0.0889, -0.3150]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1544,  0.1107, -0.2573],\n",
      "          [-0.1713, -0.1320,  0.0073],\n",
      "          [ 0.1122,  0.0414, -0.3133]]],\n",
      "\n",
      "\n",
      "        [[[-0.1221, -0.0183, -0.0586],\n",
      "          [-0.0838,  0.0673, -0.0778],\n",
      "          [ 0.0657, -0.2499, -0.2342]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0515, -0.0394, -0.2500],\n",
      "          [ 0.3276, -0.2431,  0.1887],\n",
      "          [ 0.0004,  0.1599,  0.0464]]],\n",
      "\n",
      "\n",
      "        [[[-0.2315, -0.1795, -0.2001],\n",
      "          [-0.0274,  0.0971,  0.2152],\n",
      "          [ 0.0516,  0.2813, -0.0076]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2092, -0.1443, -0.3288],\n",
      "          [ 0.2909, -0.2365, -0.0917],\n",
      "          [-0.1670,  0.2744, -0.1557]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0716, -0.3143,  0.1391, -0.3093, -0.0573,  0.0765, -0.2810, -0.3212,\n",
      "         0.0348, -0.2457,  0.0735,  0.1015,  0.0725,  0.2741,  0.0906,  0.0055,\n",
      "         0.1227, -0.2916, -0.1480, -0.1600,  0.1936,  0.2509,  0.0175, -0.0393,\n",
      "        -0.0735, -0.1952, -0.1302,  0.1759, -0.0684, -0.0098, -0.1555, -0.1967],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[-0.0568, -0.0201, -0.0304],\n",
      "          [-0.0337, -0.0242, -0.0323],\n",
      "          [-0.0119, -0.0344, -0.0250]],\n",
      "\n",
      "         [[ 0.0553, -0.0345, -0.0252],\n",
      "          [ 0.0053,  0.0493,  0.0057],\n",
      "          [ 0.0426,  0.0482, -0.0153]],\n",
      "\n",
      "         [[-0.0413, -0.0048,  0.0202],\n",
      "          [-0.0304, -0.0173, -0.0250],\n",
      "          [-0.0016, -0.0222, -0.0337]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0397, -0.0126, -0.0100],\n",
      "          [ 0.0532, -0.0468, -0.0358],\n",
      "          [-0.0312,  0.0150,  0.0117]],\n",
      "\n",
      "         [[ 0.0118, -0.0490, -0.0174],\n",
      "          [ 0.0279,  0.0217, -0.0231],\n",
      "          [-0.0541,  0.0329,  0.0180]],\n",
      "\n",
      "         [[ 0.0547, -0.0534,  0.0436],\n",
      "          [ 0.0485, -0.0025, -0.0188],\n",
      "          [-0.0127, -0.0087, -0.0312]]],\n",
      "\n",
      "\n",
      "        [[[-0.0007,  0.0223,  0.0423],\n",
      "          [ 0.0370, -0.0035,  0.0428],\n",
      "          [ 0.0257,  0.0324,  0.0480]],\n",
      "\n",
      "         [[ 0.0488, -0.0015,  0.0278],\n",
      "          [-0.0331,  0.0420, -0.0429],\n",
      "          [ 0.0543, -0.0438, -0.0249]],\n",
      "\n",
      "         [[-0.0472,  0.0556,  0.0069],\n",
      "          [-0.0427,  0.0109,  0.0201],\n",
      "          [-0.0011, -0.0163, -0.0426]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0354,  0.0472,  0.0348],\n",
      "          [-0.0301,  0.0122,  0.0021],\n",
      "          [-0.0423,  0.0475, -0.0451]],\n",
      "\n",
      "         [[-0.0049,  0.0277,  0.0067],\n",
      "          [ 0.0224, -0.0108,  0.0356],\n",
      "          [ 0.0235,  0.0047, -0.0062]],\n",
      "\n",
      "         [[-0.0506,  0.0192,  0.0131],\n",
      "          [ 0.0486,  0.0563, -0.0156],\n",
      "          [-0.0286, -0.0056,  0.0543]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0481,  0.0238, -0.0555],\n",
      "          [ 0.0282, -0.0098,  0.0244],\n",
      "          [ 0.0232, -0.0022, -0.0002]],\n",
      "\n",
      "         [[ 0.0506,  0.0516, -0.0177],\n",
      "          [ 0.0474,  0.0183, -0.0480],\n",
      "          [-0.0401, -0.0069, -0.0475]],\n",
      "\n",
      "         [[ 0.0071, -0.0485,  0.0162],\n",
      "          [ 0.0127, -0.0062,  0.0126],\n",
      "          [-0.0505,  0.0429,  0.0208]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0414, -0.0008, -0.0273],\n",
      "          [-0.0318,  0.0063, -0.0535],\n",
      "          [ 0.0278, -0.0041,  0.0520]],\n",
      "\n",
      "         [[-0.0052,  0.0231,  0.0330],\n",
      "          [-0.0194, -0.0422,  0.0204],\n",
      "          [-0.0322, -0.0259, -0.0205]],\n",
      "\n",
      "         [[-0.0161,  0.0442, -0.0502],\n",
      "          [ 0.0240,  0.0588, -0.0285],\n",
      "          [ 0.0115,  0.0236, -0.0394]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0381,  0.0479, -0.0292],\n",
      "          [-0.0139,  0.0289,  0.0309],\n",
      "          [-0.0300,  0.0362,  0.0568]],\n",
      "\n",
      "         [[-0.0078, -0.0347,  0.0092],\n",
      "          [ 0.0204,  0.0158, -0.0055],\n",
      "          [ 0.0226,  0.0212,  0.0243]],\n",
      "\n",
      "         [[ 0.0559,  0.0268,  0.0004],\n",
      "          [ 0.0524, -0.0174, -0.0222],\n",
      "          [-0.0268,  0.0421,  0.0065]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0052,  0.0272,  0.0446],\n",
      "          [ 0.0408, -0.0519, -0.0532],\n",
      "          [ 0.0419, -0.0319, -0.0039]],\n",
      "\n",
      "         [[ 0.0281, -0.0467,  0.0012],\n",
      "          [ 0.0154, -0.0339,  0.0560],\n",
      "          [ 0.0503,  0.0528, -0.0285]],\n",
      "\n",
      "         [[-0.0190,  0.0006,  0.0435],\n",
      "          [ 0.0302,  0.0407, -0.0450],\n",
      "          [ 0.0555, -0.0543, -0.0152]]],\n",
      "\n",
      "\n",
      "        [[[-0.0061, -0.0445,  0.0410],\n",
      "          [-0.0468, -0.0050,  0.0082],\n",
      "          [ 0.0015, -0.0062, -0.0374]],\n",
      "\n",
      "         [[ 0.0286,  0.0030,  0.0232],\n",
      "          [-0.0584, -0.0045,  0.0512],\n",
      "          [-0.0509,  0.0107, -0.0108]],\n",
      "\n",
      "         [[-0.0409,  0.0470, -0.0355],\n",
      "          [ 0.0154,  0.0545,  0.0118],\n",
      "          [-0.0466, -0.0163,  0.0119]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0290, -0.0006,  0.0060],\n",
      "          [ 0.0161,  0.0415, -0.0209],\n",
      "          [ 0.0089,  0.0578,  0.0340]],\n",
      "\n",
      "         [[ 0.0060,  0.0070,  0.0452],\n",
      "          [ 0.0159,  0.0159, -0.0334],\n",
      "          [ 0.0432, -0.0523, -0.0561]],\n",
      "\n",
      "         [[-0.0100, -0.0287, -0.0375],\n",
      "          [ 0.0059, -0.0135,  0.0298],\n",
      "          [ 0.0543, -0.0118, -0.0182]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0211, -0.0208, -0.0589],\n",
      "          [ 0.0572,  0.0241, -0.0536],\n",
      "          [-0.0524, -0.0151, -0.0105]],\n",
      "\n",
      "         [[-0.0475, -0.0496,  0.0396],\n",
      "          [ 0.0037,  0.0173,  0.0384],\n",
      "          [-0.0202, -0.0013, -0.0237]],\n",
      "\n",
      "         [[-0.0454,  0.0323,  0.0181],\n",
      "          [-0.0556, -0.0330, -0.0353],\n",
      "          [ 0.0573,  0.0578, -0.0420]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0403, -0.0520, -0.0209],\n",
      "          [ 0.0496, -0.0292, -0.0218],\n",
      "          [ 0.0209,  0.0251,  0.0343]],\n",
      "\n",
      "         [[ 0.0260, -0.0422, -0.0269],\n",
      "          [ 0.0533, -0.0372,  0.0530],\n",
      "          [ 0.0518,  0.0334, -0.0091]],\n",
      "\n",
      "         [[-0.0190, -0.0120, -0.0307],\n",
      "          [ 0.0314,  0.0151, -0.0012],\n",
      "          [-0.0387,  0.0211, -0.0121]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-2.2323e-02, -4.9427e-02, -1.5335e-02,  3.1440e-02, -5.1794e-02,\n",
      "        -7.7806e-04, -1.9464e-02, -4.5573e-02, -2.8560e-02,  5.3111e-03,\n",
      "        -1.8013e-02,  5.4651e-02, -2.1318e-02, -5.3061e-02,  8.4124e-03,\n",
      "         2.9009e-02, -1.3801e-02,  3.4828e-02,  2.0392e-02, -1.4084e-02,\n",
      "         5.0318e-02,  5.1617e-02,  5.3598e-04, -5.8876e-02,  1.9800e-02,\n",
      "         8.6591e-04, -2.5403e-02, -5.7382e-02, -3.5708e-02, -5.2119e-02,\n",
      "        -5.7347e-02, -3.3110e-02, -5.8371e-02,  5.5077e-02,  4.4143e-02,\n",
      "        -3.3513e-02, -2.8456e-02, -2.9084e-02, -2.0385e-02, -2.2262e-05,\n",
      "         3.4970e-02,  9.6513e-03,  6.2030e-03, -2.4768e-02, -1.6782e-02,\n",
      "         1.3788e-02, -1.0412e-02,  5.1213e-02,  4.3229e-02, -9.1321e-03,\n",
      "        -3.6476e-02, -6.2489e-03, -1.6248e-02,  5.7272e-02,  2.3953e-02,\n",
      "         3.4671e-02, -2.7881e-02, -5.3911e-02, -5.7051e-02,  2.7809e-02,\n",
      "        -3.7414e-02,  4.4550e-02,  1.1419e-02, -5.8462e-02],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0163, -0.0250, -0.0081,  ..., -0.0110,  0.0225,  0.0017],\n",
      "        [-0.0313, -0.0290,  0.0177,  ...,  0.0150,  0.0399, -0.0117],\n",
      "        [-0.0068,  0.0409, -0.0323,  ...,  0.0414,  0.0282,  0.0170],\n",
      "        ...,\n",
      "        [-0.0420,  0.0366, -0.0411,  ...,  0.0181,  0.0369, -0.0346],\n",
      "        [-0.0263,  0.0149, -0.0073,  ..., -0.0399, -0.0074, -0.0358],\n",
      "        [ 0.0002,  0.0039,  0.0266,  ..., -0.0281, -0.0206,  0.0250]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0077,  0.0103, -0.0132, -0.0026, -0.0040, -0.0175, -0.0046, -0.0177,\n",
      "        -0.0043, -0.0128], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c0923f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "train_total_batch = len(train_loader)\n",
    "test_total_batch = len(test_loader)\n",
    "print(train_total_batch)\n",
    "print(test_total_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ce21ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, cost:0.7299035787582397\n",
      "epoch:1, cost:0.36254560947418213\n",
      "epoch:2, cost:0.2660159766674042\n",
      "epoch:3, cost:0.21473556756973267\n",
      "epoch:4, cost:0.17717625200748444\n",
      "epoch:5, cost:0.14501798152923584\n",
      "epoch:6, cost:0.12157994508743286\n",
      "epoch:7, cost:0.1050180196762085\n",
      "epoch:8, cost:0.0912265032529831\n",
      "epoch:9, cost:0.07215183973312378\n",
      "epoch:10, cost:0.06477440148591995\n",
      "epoch:11, cost:0.062059711664915085\n",
      "epoch:12, cost:0.04746905341744423\n",
      "epoch:13, cost:0.04100324586033821\n",
      "epoch:14, cost:0.03030475415289402\n",
      "epoch:15, cost:0.03258734568953514\n",
      "epoch:16, cost:0.027742844074964523\n",
      "epoch:17, cost:0.02085844799876213\n",
      "epoch:18, cost:0.03712589293718338\n",
      "epoch:19, cost:0.021218230947852135\n",
      "epoch:20, cost:0.00812607817351818\n",
      "epoch:21, cost:0.0023559723049402237\n",
      "epoch:22, cost:0.03917263448238373\n",
      "epoch:23, cost:0.02208077535033226\n",
      "epoch:24, cost:0.011585459113121033\n",
      "epoch:25, cost:0.01791551522910595\n",
      "epoch:26, cost:0.009525132365524769\n",
      "epoch:27, cost:0.017792372032999992\n",
      "epoch:28, cost:0.014438909478485584\n",
      "epoch:29, cost:0.007432231213897467\n"
     ]
    }
   ],
   "source": [
    "for epoch  in range(epochs):\n",
    "    avg_cost=0\n",
    "\n",
    "    for X, Y in train_loader:\n",
    "        X=X.to(device)\n",
    "        Y=Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_hat=model(X)\n",
    "        cost = crit(y_hat, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost/test_total_batch\n",
    "    print(f'epoch:{epoch}, cost:{avg_cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "287aec09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY :  {tensor(0.9897)}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x_test = mnist_test.data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    y_test = mnist_test.targets.to(device)\n",
    "\n",
    "    pred=model(x_test)\n",
    "    correct_pred=torch.argmax(pred, -1) == y_test\n",
    "    accuracy = correct_pred.float().mean()\n",
    "    print(f'ACCURACY : ', {accuracy})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
